{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlxtend.preprocessing\n",
    "import mlxtend.frequent_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc69a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following, you need to go through the steps of extracting associtaion rules\n",
    "# from a dataset that contains information on users and what movies that have watched and liked\n",
    "# The final goal is to create some movie recommendations in the form of rules\n",
    "\n",
    "# Loading the data, it is the Movie_subset.csv file\n",
    "\n",
    "movie_data = pd.read_csv('Movie_subset.csv')\n",
    "\n",
    "# Look at the data (using .head()): we have one column for each user-movie pair (similar structure we had with retail data)\n",
    "# The important columns are userId and title\n",
    "\n",
    "movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a44325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the transactional format as it is done in the lecture example\n",
    "# First create a list of lists (one list for each user, combined in a list)\n",
    "\n",
    "movie_list = movie_data.groupby(['userId'])['title'].apply(list).values.tolist()\n",
    "\n",
    "print(movie_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the transactional format\n",
    "\n",
    "# Define the TransactionEncoder\n",
    "encoder = mlxtend.preprocessing.TransactionEncoder().fit(movie_list)\n",
    "\n",
    "# Transform the data\n",
    "encoded_data = encoder.transform(movie_list)\n",
    "\n",
    "# Finally convert it to dataframe\n",
    "movie_trans = pd.DataFrame(encoded_data, columns = encoder.columns_)\n",
    "\n",
    "print(movie_trans.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945047c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check size of data\n",
    "# Answer: 100 users and 4508 movies\n",
    "\n",
    "movie_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c4e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most frequent movies\n",
    "# Top 3: The Matrix, American Beauty, Fight Club \n",
    "\n",
    "movie_trans.sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fb2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with frequent itemsets, and specify min_support 0.3 and max_len 3\n",
    "# How many itemsets we obtain?\n",
    "# Answer: We have 170 itemsets (use len())\n",
    "\n",
    "frequent_itemsets = mlxtend.frequent_patterns.apriori(movie_trans, min_support = 0.3, max_len = 3, use_colnames = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86882bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra task not done in the course videos: \n",
    "# - create a column with the length of the itemset in the row (hint: use apply)\n",
    "# - check how many itemsets you have with 3 items (18 itemsets)\n",
    "\n",
    "frequent_itemsets['item_len'] = frequent_itemsets['itemsets'].apply(len)\n",
    "\n",
    "frequent_itemsets[frequent_itemsets['item_len'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb41895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different combinations of support and max_len, and impact on the number of rules\n",
    "# min_support 0.3, max_len 4: 171 itemsets\n",
    "# min_support 0.2, max_len 3: 5251 itemsets\n",
    "# min_support 0.2, max_len 3: 9348 itemsets\n",
    "# min_support 0.4, max_len 4: 16 itemsets\n",
    "# min_support 0.35, max_len 4: 57 itemsets\n",
    "\n",
    "print(len(mlxtend.frequent_patterns.apriori(movie_trans, min_support = 0.3, max_len = 4, use_colnames = True)))\n",
    "print(len(mlxtend.frequent_patterns.apriori(movie_trans, min_support = 0.2, max_len = 3, use_colnames = True)))\n",
    "print(len(mlxtend.frequent_patterns.apriori(movie_trans, min_support = 0.2, max_len = 4, use_colnames = True)))\n",
    "print(len(mlxtend.frequent_patterns.apriori(movie_trans, min_support = 0.4, max_len = 4, use_colnames = True)))\n",
    "print(len(mlxtend.frequent_patterns.apriori(movie_trans, min_support = 0.35, max_len = 4, use_colnames = True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec217c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go with min_support 0.3 and max_len 4 and create the frequent itemsets with .apriori\n",
    "\n",
    "frequent_itemsets = mlxtend.frequent_patterns.apriori(movie_trans, min_support = 0.3, max_len = 4, use_colnames = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e8848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with a strong condition for confidence when using the association_rules function, min_threshold 0.9\n",
    "# Do you get anything useful?\n",
    "\n",
    "\n",
    "rules = mlxtend.frequent_patterns.association_rules(frequent_itemsets, metric = \"confidence\", min_threshold = 0.95)\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf49aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with confidence 0.8\n",
    "# How many rules are extracted? (Answer: 90)\n",
    "# After this, you can experiment with lift and also different thresholds\n",
    "\n",
    "rules = mlxtend.frequent_patterns.association_rules(frequent_itemsets, metric = \"confidence\", min_threshold = 0.8)\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93299934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra task: what movie would you recommend to somebody who has seen Pulp Fiction and Fight club \n",
    "# based on the rules extracted with min_confidence 0.8?\n",
    "# Answer: 3 rules, recommend American Beauty, The Matrix or The Silence of the Lambs\n",
    "\n",
    "selection = rules['antecedents'].apply(lambda x: 'Pulp Fiction' in x and 'Fight Club' in x)\n",
    "rules[selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fed19f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f798a5",
   "metadata": {},
   "source": [
    "### Regression with Decision trees and random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already now how to solve one type of supervised problems with tree-based models: classification\n",
    "# However, these methods can also be used for the other class of supervised learning: regression\n",
    "# In the following we will go through the process of applying Regression Trees and Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb6fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the important libraries\n",
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Classification performance evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Decision trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "# Random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Grid search\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4924cc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>origin</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>US</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>Asia</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>Europe</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  displ   hp  weight  accel  origin  size\n",
       "0  18.0  250.0   88    3139   14.5      US  15.0\n",
       "1   9.0  304.0  193    4732   18.5      US  20.0\n",
       "2  36.1   91.0   60    1800   16.4    Asia  10.0\n",
       "3  18.5  250.0   98    3525   19.0      US  15.0\n",
       "4  34.3   97.0   78    2188   15.8  Europe  10.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The main idea of classification tree was to create branches based on optimal splits, and \n",
    "# the predicted outcome in the branch is the class that has the majority of datapoints in the branch\n",
    "# In Regression trees, we have a similar idea: we try to split our data (creating branches)\n",
    "# in a way that create homogeneous subsets of data, i.e. similar datapoints\n",
    "# In case of classification it means that we want points to be mainly from the same class\n",
    "# In case of regression, it means that want the outcome value of the points to be as close to each other as possible\n",
    "# In practice, we use the mean squred error for this\n",
    "# And the prediction in this case, when we decided that a branch is final, is the average of the values in the branch\n",
    "# We call this Regression tree, in contrast to classification trees\n",
    "\n",
    "# We will start with a dataset describing cars\n",
    "# We try whehter some measurements can predict the fuel consumption of the car\n",
    "\n",
    "cars = pd.read_csv('auto.csv')\n",
    "\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c4360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we proceed, we have one data transformation task: covert origin to dummy variables\n",
    "# We create dummy variables, drop one to create one-hot encoding, join it with the original dataset and drop origin column\n",
    "\n",
    "cars_origin = pd.get_dummies(cars.origin, drop_first=True)\n",
    "\n",
    "cars = pd.concat([cars, cars_origin], axis = 1).drop('origin', axis = 1)\n",
    "\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To perform regression with trees, we have a new function, DecisionTreeRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# In regression problems the error is not measured by the confusion matrix\n",
    "# There are alternative measures, mean squared error is one that is typically used\n",
    "# We want it to get as low as possible (error = prediction - original value, we want the error to be small)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# The start of the process is the same, we create train and test sets\n",
    "X = cars.iloc[:,1:]\n",
    "y = cars['mpg']\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# We create an instance of a DecisionTreeRegressor \n",
    "cars_reg = DecisionTreeRegressor(random_state = 0)\n",
    "\n",
    "# Finally we fit the data\n",
    "\n",
    "cars_tree_fit = cars_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d50279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also visualize the tree\n",
    "\n",
    "viz_tree = tree.export_graphviz(cars_tree_fit, out_file=None, feature_names=X.columns, )\n",
    "\n",
    "# Then we can draw the tree\n",
    "\n",
    "graph = graphviz.Source(viz_tree) \n",
    "\n",
    "# Save it in an external file\n",
    "graph.render(\"viz_tree\")\n",
    "\n",
    "# As we can see when we open the file, the same thing happened as with decision tree: theere is no pruning, each branch has\n",
    "# only one node, as here we do not differentiate classes but numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9165ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see how we perform we create prediction and calculate MSE\n",
    "\n",
    "y_pred = cars_tree_fit.predict(X_test)\n",
    "\n",
    "mse_1 = MSE(y_test, y_pred)\n",
    "\n",
    "print('MSE of unpruned tree is', mse_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb81583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of rgression trees it is even more crucial to prune the tree\n",
    "# Let's do that using some available attributes (we have most of the same ones as with classification tree)\n",
    "\n",
    "# We limit the depth of the tree, and we require to have at least 10 nodes in each branch\n",
    "cars_reg_2 = DecisionTreeRegressor(max_depth = 8, min_samples_leaf = 10, random_state = 0)\n",
    "\n",
    "# Finally we fit the data\n",
    "\n",
    "cars_tree_fit_2 = cars_reg_2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cars_tree_fit_2.predict(X_test)\n",
    "\n",
    "mse_2 = MSE(y_test, y_pred)\n",
    "\n",
    "# We improved a lot. When we have regression, we do not have any spcific error value to target\n",
    "# We just try to decrease this value as much as we can by chaning parameters\n",
    "\n",
    "print('MSE of pruned tree is', mse_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc5b64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>origin</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>US</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>Asia</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>Europe</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  displ   hp  weight  accel  origin  size\n",
       "0  18.0  250.0   88    3139   14.5      US  15.0\n",
       "1   9.0  304.0  193    4732   18.5      US  20.0\n",
       "2  36.1   91.0   60    1800   16.4    Asia  10.0\n",
       "3  18.5  250.0   98    3525   19.0      US  15.0\n",
       "4  34.3   97.0   78    2188   15.8  Europe  10.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = pd.read_csv('auto.csv')\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a569f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have an idea how good we are, compare it to linear regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "cars_lr = LinearRegression()\n",
    "\n",
    "cars_lr_fit = cars_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cars_lr_fit.predict(X_test)\n",
    "\n",
    "mse_3 = MSE(y_test, y_pred)\n",
    "\n",
    "# Simple linear regression performs better\n",
    "\n",
    "print('MSE of linear regression is', mse_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37266355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can utilize our knowledge of gridsearch and try to improve\n",
    "\n",
    "# Define params_dt\n",
    "params_dt = {'max_depth': [2, 3, 4],'min_samples_leaf': [10, 15, 20, 25]}\n",
    "\n",
    "grid_dt = GridSearchCV(estimator=cars_reg, param_grid=params_dt, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f68b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can extract the best model\n",
    "\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# and evaluate prediction based on that\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mse_4 = MSE(y_test, y_pred)\n",
    "\n",
    "# We improved somewhat, but still worse than linear regression\n",
    "\n",
    "print('MSE of optimized regression tree is', mse_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30fc4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also create Random forest for regression\n",
    "# They work the same way as regression trees\n",
    "\n",
    "# We need to import the new function\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# We can create an  instance of a regressor, with the same main parameter, number of base estimators\n",
    "\n",
    "cars_rf = RandomForestRegressor(n_estimators = 200, random_state = 0)\n",
    "                           \n",
    "# We fit the training set            \n",
    "cars_rf.fit(X_train, y_train)  \n",
    "\n",
    "# Create predictions\n",
    "y_pred_rf = cars_rf.predict(X_test)\n",
    "\n",
    "mse_rf = MSE(y_test, y_pred_rf)\n",
    "\n",
    "# As we can see, without any parameter selection, we already got better results than linear regression\n",
    "\n",
    "print('MSE of random forests is', mse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d9bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to optimize it\n",
    "\n",
    "# We define the grid\n",
    "grid = dict(max_depth = [4, 6, 8], min_samples_leaf = [10, 15, 20])\n",
    "\n",
    "forest_cars = RandomForestRegressor(n_estimators = 200, random_state = 0)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=forest_cars, param_grid=grid, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# Print out the best result\n",
    "print(\"Best result is obtained using\", grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fafd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_rf = RandomForestRegressor(n_estimators = 200, max_depth = 6, min_samples_leaf = 6, random_state = 0)\n",
    "                           \n",
    "# We fit the training set            \n",
    "cars_rf_fit = cars_rf.fit(X_train, y_train)  \n",
    "\n",
    "# Create predictions\n",
    "y_pred_rf = cars_rf_fit.predict(X_test)\n",
    "\n",
    "mse_rf = MSE(y_test, y_pred_rf)\n",
    "\n",
    "# As we can see, without any parameter selection, we already got better results than linear regression\n",
    "\n",
    "print('MSE of random forests is', mse_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e53678",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "\n",
    "It can be important to also have an idea when applying tree based model, to understand what variables have the greates impact on determining the outcome. This is not really possible to see from the tree itself, especially not from a forest, but it can be extracted easily from a model. This works the same way for classification and regression problem, we will look at it now for thecreated regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769064e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First try with decision trees\n",
    "# We can simply obtain feature importance using feature_importances_\n",
    "# We check our best model for regression trees\n",
    "\n",
    "# We can see that only three varibales play a role in the prediction\n",
    "\n",
    "pd.Series(data = best_model.feature_importances_, index= X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eab955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same for the best random forest\n",
    "# In this case we have at least some importance assigned to each variable, but the best is the same\n",
    "# Interestingly, size, that had no role in the regression tree model, is the second most important here\n",
    "\n",
    "pd.Series(data = cars_rf_fit.feature_importances_, index= X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33275b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

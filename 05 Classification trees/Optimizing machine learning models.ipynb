{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook we will look at how to improve the performance of machine learning models\n",
    "# by trying to identify optmial values for some parameters that guide the learning process\n",
    "# For example, as we have seen, we can adjust the maximum depth of a decision tree\n",
    "# But how do we know how to set it to maximize accuracy, and how it interacts for example with \n",
    "# the minimum split, another parameter? This process is called (hyper)parameter tuning\n",
    "# and it is a crucial part of the machine learning model building process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f1b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the main libraries, also for logistic regression and decision trees\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Classification performance evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Decision trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035469cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will start with a dataset about credit card owners, and task is to build a model\n",
    "# to identify those that will not pay back their creadit next month\n",
    "# So this is a binary classification problem\n",
    "\n",
    "credit = pd.read_csv('credit-card-full.csv')\n",
    "\n",
    "# We have 30000 data points, 1 ID column, 23 predictors, and 1 binary outcome\n",
    "print(credit.shape)\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to build our first model with logistic regression\n",
    "\n",
    "X = credit[credit.columns[1:24]]\n",
    "y = credit['default payment next month']\n",
    "\n",
    "# Then we crate training and test set, with 25% of the data in the test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "credit_logistic = LogisticRegression()\n",
    "\n",
    "# As we can see, the algorithm could not construct a good enough model\n",
    "credit_logistic.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It happens sometimes, but we need to have at least a first model before we can fine-tune it\n",
    "# As the error message suggest, we can try to change two things first: increase the number of iterations, \n",
    "# or change the solver (we do not perform scaling here, although that is an option\n",
    "# as we know, logistic regression does not require scaling, the results will be correct, but \n",
    "# scaling can speed up the model building, requiring less iterations)\n",
    "\n",
    "# Let's try to increase number of iterations to 500\n",
    "credit_logistic = LogisticRegression(max_iter = 500)\n",
    "# The model is constructed now\n",
    "credit_logistic.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the performance\n",
    "pred_logistic = credit_logistic.predict(X_test)\n",
    "print(confusion_matrix(y_test,pred_logistic))\n",
    "\n",
    "# As we can see, the results are very bad, we misclassify all the default cases\n",
    "# We get the error message because some measures cannot be calculated when we do not predict one of the classes at all\n",
    "print(classification_report(y_test,pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b1785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems goig with the default options, we cannot build a good model, so we need to change some attributes\n",
    "# A basic way is that wwe just try to change values one by one\n",
    "# In case like this, an intuitive solution could be to tell python that we want to increase the importance of class1\n",
    "# We can do this using class_weight, as we did with decision trees\n",
    "# There is a good option, 'balanced', that takes into consideration that one of the classes is smaller\n",
    "# and adds extra importance based on the proportionality from the data\n",
    "\n",
    "credit_logistic = LogisticRegression(max_iter = 500, class_weight = 'balanced')\n",
    "credit_logistic.fit(X_train,y_train)\n",
    "pred_logistic = credit_logistic.predict(X_test)\n",
    "\n",
    "# As we can see, while the accuracy decreased, now we have many default customer correctly identified\n",
    "# Even if we know how to optimize parameters, we still need to understand the business problem\n",
    "# In this case, we would need to know how much the different misclassifications cost to the bank\n",
    "# Is it worth to have alsmot 3000 false alarms to identify approx. 75% of default cases\n",
    "print(confusion_matrix(y_test,pred_logistic))\n",
    "print(classification_report(y_test,pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b988c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another important parameter we can try is C, intuitively it prevents overfitting, but can also \n",
    "# significantly improve performance\n",
    "\n",
    "credit_logistic = LogisticRegression(max_iter = 500, class_weight = 'balanced', C = 0.1)\n",
    "credit_logistic.fit(X_train,y_train)\n",
    "pred_logistic = credit_logistic.predict(X_test)\n",
    "\n",
    "# If you play around with the code and try different values for C, you will see that \n",
    "# it does not really change the final performance\n",
    "print(confusion_matrix(y_test,pred_logistic))\n",
    "print(classification_report(y_test,pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68387b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to try multiple options for a parameter, we can use iteration\n",
    "# For example, there are different penalty functions available, this is also related to overfitting\n",
    "# We can check which one leads to the best performance\n",
    "\n",
    "penalty_list = ['l1', 'l2', 'elasticnet', 'none']\n",
    "for pen in penalty_list:\n",
    "    # Specify attributes\n",
    "    try:\n",
    "        credit_logistic = LogisticRegression(max_iter = 500, class_weight = 'balanced', penalty = pen)\n",
    "        credit_logistic.fit(X_train,y_train)\n",
    "        pred_logistic = credit_logistic.predict(X_test)\n",
    "        rep_cred = classification_report(y_test,pred_logistic, output_dict = True)\n",
    "        # Print relevant information in each step\n",
    "        print('With penalty', pen, 'recall for default class is', rep_cred['1']['recall'],\n",
    "              'and accuracy is', rep_cred['accuracy'])\n",
    "    except:\n",
    "        print('We cannot use', pen, 'with the current solver.')\n",
    "        \n",
    "# It seems it does not make a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ba4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While can try to iterate over different parameters, double iterate over possible combinations etc.\n",
    "# But we have a structured and convenient way to do that in python: Grid search\n",
    "# The main idea is that we specify a set of values of interest for each parameter, and \n",
    "# a model will be built for each combination, with the best one selected as the optimal model\n",
    "\n",
    "# We need a new function for this\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# We start by initializing the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# We can specify possible values for the number of iterations\n",
    "iterations = [500, 600, 700, 800]\n",
    "\n",
    "# We can try different C values\n",
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Class weights\n",
    "weights = ['balanced', {0:0.1, 1:0.9}]\n",
    "\n",
    "# We define the grid as a dictionary, using the name of parameters as defined in LogistiRegression as keys\n",
    "# We will have 4x5x2=40 possible combinations, i.e. 40 different models will be tested\n",
    "\n",
    "grid = dict(max_iter = iterations, C = c_values, class_weight = weights)\n",
    "\n",
    "# We specify the grid search\n",
    "# Estimator is the initial model, param_grid is the dictionary specified above\n",
    "# We can also specify what performance measure we want to optimize\n",
    "# We can try with recall\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, scoring='recall')\n",
    "\n",
    "# We fit the training data\n",
    "# Note: the grid model building will automatically employ cross-validation\n",
    "# The default option is 5 folds that we will use now\n",
    "# So we do not need to use training and test set (as we have seen in cross-validation in BA1)\n",
    "\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# Print out the best results\n",
    "# It tells us what parameters ween need to chose to obtain the model with the best possible recall\n",
    "# You can try with different settings and change also scoring to, e.g. accuracy\n",
    "\n",
    "print(\"Best result is\", grid_result.best_score_, 'using', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd8f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know the idea now, let's try decision trees\n",
    "\n",
    "credit_tree = DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "# This case we can specify possible values for \n",
    "# optimality criterion\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "# Maximum depth of the tree\n",
    "max_depth = [2,4,6,8,10,12]\n",
    "\n",
    "# Class weights\n",
    "weights = ['balanced', {0:0.1, 1:0.9}]\n",
    "\n",
    "# We define the grid, 24 possible models\n",
    "grid = dict(criterion = criterion, max_depth = max_depth, class_weight = weights)\n",
    "\n",
    "# We specify the grid search\n",
    "# In this case we will use a different scoring method, AUC that captures different perspectives at the same time\n",
    "\n",
    "grid_search = GridSearchCV(estimator=credit_tree, param_grid=grid, scoring='roc_auc')\n",
    "\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# Print out the best result\n",
    "print(\"Best result is\", grid_result.best_score_, 'using', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5320ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the best model\n",
    "credit_tree = DecisionTreeClassifier(max_depth = 6, criterion = 'gini', class_weight= {0:0.1, 1:0.9}, random_state = 42)\n",
    "tree_model = credit_tree.fit(X,y)\n",
    "pred_tree = tree_model.predict(X)\n",
    "print(confusion_matrix(y,pred_tree))\n",
    "print(classification_report(y,pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f7159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b546db1",
   "metadata": {},
   "source": [
    "### Recommendation systems basics\n",
    "In the following we will go through the basics of creating recommendations with the tools available in Python. We start with some basic analysis that focuses on identifying similar movies as the basis of recommendation, and then we look at more specifically collaborative filtering ( we will briefly look at content-based recommendations after we are familiar with text analysis in the last week)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5299452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we load the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a459234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the analysis we will work with the dataset we have used before, the MovieLense data\n",
    "# We have users who rated the movies they have watched in the past\n",
    "# We have already created a type of recommendation using association rules\n",
    "# We will also start here with some general ideas on how to find similar movies based on ratings\n",
    "# but evetually we want to create personalized recommendations, not only general rules\n",
    "\n",
    "#  We have one file with all the information already combined\n",
    "\n",
    "ratings = pd.read_csv('user_ratings.csv')\n",
    "\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we come to the recommendations, we can perform some data exploration\n",
    "# First looking at the most frequently reated movies\n",
    "# This could also be seen as the most trivial solution: recommending the most watched movie\n",
    "#  In this case Forest Gump\n",
    "\n",
    "ratings.title.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cdf7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can improve this slightly if we consider also rating\n",
    "# First we can calculate the mean of the ratings given to each title\n",
    "mean_rating = ratings[[\"title\", \"rating\"]].groupby('title').mean()\n",
    "\n",
    "# Order the entries by highest average rating to lowest\n",
    "sorted_mean_rating = mean_rating.sort_values(by=\"rating\", ascending=False)\n",
    "\n",
    "# We can check the best movies\n",
    "# We have a problem: these are movies that were only watched by a handful of people who watched them\n",
    "# but this is most likely not a good basis for recommendations\n",
    "\n",
    "sorted_mean_rating.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To correct this problem, we can filter out movies that were not rated by a sufficient number of users\n",
    "\n",
    "# First we create a list of movies appearing > 50 times in the dataset\n",
    "movie_popularity = ratings[\"title\"].value_counts()\n",
    "popular_movies = movie_popularity[movie_popularity > 50].index\n",
    "\n",
    "# We will have 437 movies left\n",
    "print(popular_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use this list to filter the original DataFrame\n",
    "popular_movies_rankings = ratings[ratings[\"title\"].isin(popular_movies)]\n",
    "\n",
    "# We can now calculate average rating again for this filtered list\n",
    "popular_movies_average = popular_movies_rankings[[\"title\", \"rating\"]].groupby('title').mean()\n",
    "\n",
    "# Based on this, we would recommend The Shawshank Redemption as the highest rated movie watched by at least 100 users\n",
    "print(popular_movies_average.sort_values(by=\"rating\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Still a simple question to ask is: if somebody just finished watching a specific movie, what should be the next to recommend?\n",
    "# As simple strategy to answer this would be to check which other movie has been watched\n",
    "# most frequently together with that movie\n",
    "\n",
    "# For this, we will need to create all the pairs of movies that have been rated by at least one user together\n",
    "#  For this we will make use of a function that is imported here\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "# To see how this works, lets try it for only one user\n",
    "\n",
    "data_1 = ratings[ratings.userId == 1]\n",
    "\n",
    "# Using permutations, we can create a list in which each element is a pair of movie that both have been watched by the user\n",
    "# If we do this for all the users, we can count how many users have watched a given pair of movies \n",
    "\n",
    "list(permutations(data_1.title.values, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a function that creates the pairs and arranges them in two columns of a dataframe\n",
    "def find_movie_pairs(x):\n",
    "  movie_pairs = pd.DataFrame(list(permutations(x.values, 2)), columns=['movie_a', 'movie_b'])\n",
    "  return movie_pairs\n",
    "\n",
    "# We can apply this to title after we group by the user column\n",
    "movie_combinations = ratings.groupby('userId')['title'].apply(find_movie_pairs)\n",
    "\n",
    "# .reset_index(drop=True)\n",
    "\n",
    "# This takes a bit of time, and we end up with 60 million pairs\n",
    "print(movie_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce999e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we group by the two columns, we will get the counts for all the pairs\n",
    "\n",
    "combination_counts = movie_combinations.groupby(['movie_a', 'movie_b']).size()\n",
    "\n",
    "combination_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adcb5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a series, we can convert it to dataframe and use it in that form\n",
    "#  We need to reset index to take the movie titles as the first two column\n",
    "\n",
    "combination_counts_df = combination_counts.to_frame(name='size').reset_index()\n",
    "\n",
    "combination_counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44362e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can find what to recommend to somebody who just watched Batman Begins\n",
    "# First we filter the data when movie_a is 'Batman Begins (2005)'\n",
    "# and then sort it by size, and check the top\n",
    "# The lord of the rings would be a good choice\n",
    "\n",
    "combination_counts_df[combination_counts_df['movie_a'] == 'Batman Begins (2005)'].sort_values('size', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c24f2",
   "metadata": {},
   "source": [
    "### Collaborative filtering\n",
    "The last method still does not consider ratings, only frequency. A general model, as introduced in the lecture, is collaborative filtering. It is based on the idea that we can find similar users/items based on the similarity of ratings. For example in user-based collaborative filtering, that assumes that if two users gave similar rating in the past, they are likely to rate future movies similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a57d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the basis of collaborative filtering, we need to create the rating matrix:\n",
    "# Rows are users and columns are movies, and each element is the rating for the given user/movie pair if available\n",
    "# This is actually a pivot table based on the columns userId, title and rating\n",
    "\n",
    "ratings_table = ratings.pivot(index='userId', columns='title', values='rating')\n",
    "\n",
    "# As you can see there is a problem\n",
    "# We actually have some users that rated the same movie several times\n",
    "# We need to identify this and exclude before we can create the ratings table\n",
    "\n",
    "print(ratings_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7760400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make it simpler, first we creat a dataframe of the three columns of interest\n",
    "\n",
    "ratings_test = ratings[['userId', 'title', 'rating']]\n",
    "\n",
    "# We can see that there are three duplicated values\n",
    "ratings_test[ratings_test.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4feb17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We can then drop duplicates, we keep the last entry, as that should be a more recent rating\n",
    "\n",
    "ratings_test.drop_duplicates(subset = ['userId', 'title'] ,keep='last', inplace = True)\n",
    "\n",
    "#  Now we should be able to create the ratings table\n",
    "\n",
    "ratings_table = ratings_test.pivot(index='userId', columns='title', values='rating')\n",
    "\n",
    "print(ratings_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76207f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next question is how to fill in missing values\n",
    "# (Specifying 0 for a missing value is not good, why?)\n",
    "# We will use a simple approach: \n",
    "\n",
    "# First we calculate the mean rating for each user\n",
    "\n",
    "avg_ratings = ratings_table.mean(axis=1)\n",
    "\n",
    "avg_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12778e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second we substract this value from the available ratings\n",
    "\n",
    "ratings_table_centered = ratings_table.sub(avg_ratings, axis=0)\n",
    "\n",
    "#  As we check, the average rating for a user will be now 0 (or a very low number), which means it becomes a neutral value\n",
    "\n",
    "ratings_table_centered.apply(np.mean, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678764c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can fill in the missing values with 0 now\n",
    "\n",
    "ratings_table_normed = ratings_table_centered.fillna(0)\n",
    "\n",
    "ratings_table_normed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a463fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the table ready, we can identify similar users and movies\n",
    "#  For this we need the cosine similarity measure\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#  We can calculate cosine similarity for all pairs of users\n",
    "\n",
    "similarities = cosine_similarity(ratings_table_normed)\n",
    "\n",
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a dataframe based on the similarities\n",
    "\n",
    "cosine_similarity_df = pd.DataFrame(similarities, index=ratings_table_normed.index, columns=ratings_table_normed.index)\n",
    "\n",
    "cosine_similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9674ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can find the most similar users for example to user 1\n",
    "#  First we select the row \n",
    "cosine_similarity_1 = cosine_similarity_df.loc[1]\n",
    "\n",
    "# We can sort these values highest to lowest\n",
    "ordered_similarities = cosine_similarity_1.sort_values(ascending=False)\n",
    "\n",
    "#  Except for 1, the most imilar user is 301\n",
    "# So if there is a movie that 301 has already rated and 1 has not, we can use 301's rating as the basis of recommendation\n",
    "print(ordered_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d52f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the same thing from the perspective of the movies \n",
    "#  We simply need to reverse the role of users and movies\n",
    "#  This can simply be done by changing the role of rows and columns in the rating table\n",
    "\n",
    "movie_ratings = ratings_table_normed.T\n",
    "\n",
    "similarities_movies = cosine_similarity(movie_ratings)\n",
    "\n",
    "cosine_similarity_movies = pd.DataFrame(similarities_movies, index=movie_ratings.index, columns=movie_ratings.index)\n",
    "\n",
    "cosine_similarity_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb62b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Now we can checl what are the most similar movies to Batman Begins based on ratings\n",
    "\n",
    "cosine_similarity_bb = cosine_similarity_movies.loc['Batman Begins (2005)']\n",
    "\n",
    "\n",
    "ordered_similarities = cosine_similarity_bb.sort_values(ascending=False)\n",
    "\n",
    "#  The most similar movies include some that we would expect\n",
    "print(ordered_similarities[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee25e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
